{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-selling products\n",
    "- The small grocery store has decided to cross-sell chewing gum with either coffee, cereal, or bread. To determine which of the three items is best to use, the store owner has performed an experiment. For one week, she sold chewing gum next to the register and recorded all transactions where it was purchased with either coffee, cereal, or bread. The transactions from that day are available as a list of lists named transactions. Each transaction is either ['coffee','gum'], ['cereal','gum'], or ['bread','gum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [['bread', 'gum'],['bread', 'gum'],['cereal', 'gum'],['coffee', 'gum'],['bread', 'gum'],['coffee', 'gum'],['coffee', 'gum'],['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['cereal', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['bread', 'gum'],\n",
    " ['coffee', 'gum'],\n",
    " ['coffee', 'gum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee: 0\n",
      "cereal: 25\n",
      "bread: 20\n"
     ]
    }
   ],
   "source": [
    "# Count the number of transactions with coffee and gum\n",
    "coffee = transactions.count(['cofee', 'gum'])\n",
    "\n",
    "# Count the number of transactions with cereal and gum\n",
    "cereal = transactions.count(['cereal', 'gum'])\n",
    "\n",
    "# Count the number of transactions with bread and gum\n",
    "bread = transactions.count(['bread', 'gum'])\n",
    "\n",
    "# Print the counts for each transaction.\n",
    "print('coffee:', coffee)\n",
    "print('cereal:', cereal)\n",
    "print('bread:', bread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for market basket analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>milk,bread,biscuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bread,milk,biscuit,cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bread,tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jam,bread,milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tea,biscuit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Transaction\n",
       "0         milk,bread,biscuit\n",
       "1  bread,milk,biscuit,cereal\n",
       "2                  bread,tea\n",
       "3             jam,bread,milk\n",
       "4                tea,biscuit"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load transactions from pandas\n",
    "groceries = pd.read_csv('data/small_grocery_store.csv')\n",
    "groceries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['milk', 'bread', 'biscuit'], ['bread', 'milk', 'biscuit', 'cereal'], ['bread', 'tea'], ['jam', 'bread', 'milk'], ['tea', 'biscuit'], ['bread', 'tea'], ['tea', 'cereal'], ['bread', 'tea', 'biscuit'], ['jam', 'bread', 'tea'], ['bread', 'milk'], ['coffee', 'orange', 'biscuit', 'cereal'], ['coffee', 'orange', 'biscuit', 'cereal'], ['coffee', 'sugar'], ['bread', 'coffee', 'orange'], ['bread', 'sugar', 'biscuit'], ['coffee', 'sugar', 'cereal'], ['bread', 'sugar', 'biscuit'], ['bread', 'coffee', 'sugar'], ['bread', 'coffee', 'sugar'], ['tea', 'milk', 'coffee', 'cereal']]\n"
     ]
    }
   ],
   "source": [
    "# Split transaction strings into lists\n",
    "transactions = groceries['Transaction'].apply(lambda t: t.split(','))\n",
    "\n",
    "# Convert DataFrame column into list of strings\n",
    "transactions = list(transactions)\n",
    "\n",
    "# Print the list of transactions\n",
    "print(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  load and prepare data, generate association rules, and then discard the subset of rules that are not useful.\n",
    "\n",
    "### Generating association rules\n",
    "- the function permutations from the module itertools can be used to quickly generate the set of all one-antecedent, one-consequent rules. We do not, of course, know which of these rules are useful. We simply know that each is a valid way to combine two items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tea', 'cereal'), ('tea', 'milk'), ('tea', 'orange'), ('tea', 'coffee'), ('tea', 'jam'), ('tea', 'biscuit'), ('tea', 'sugar'), ('tea', 'bread'), ('cereal', 'tea'), ('cereal', 'milk'), ('cereal', 'orange'), ('cereal', 'coffee'), ('cereal', 'jam'), ('cereal', 'biscuit'), ('cereal', 'sugar'), ('cereal', 'bread'), ('milk', 'tea'), ('milk', 'cereal'), ('milk', 'orange'), ('milk', 'coffee'), ('milk', 'jam'), ('milk', 'biscuit'), ('milk', 'sugar'), ('milk', 'bread'), ('orange', 'tea'), ('orange', 'cereal'), ('orange', 'milk'), ('orange', 'coffee'), ('orange', 'jam'), ('orange', 'biscuit'), ('orange', 'sugar'), ('orange', 'bread'), ('coffee', 'tea'), ('coffee', 'cereal'), ('coffee', 'milk'), ('coffee', 'orange'), ('coffee', 'jam'), ('coffee', 'biscuit'), ('coffee', 'sugar'), ('coffee', 'bread'), ('jam', 'tea'), ('jam', 'cereal'), ('jam', 'milk'), ('jam', 'orange'), ('jam', 'coffee'), ('jam', 'biscuit'), ('jam', 'sugar'), ('jam', 'bread'), ('biscuit', 'tea'), ('biscuit', 'cereal'), ('biscuit', 'milk'), ('biscuit', 'orange'), ('biscuit', 'coffee'), ('biscuit', 'jam'), ('biscuit', 'sugar'), ('biscuit', 'bread'), ('sugar', 'tea'), ('sugar', 'cereal'), ('sugar', 'milk'), ('sugar', 'orange'), ('sugar', 'coffee'), ('sugar', 'jam'), ('sugar', 'biscuit'), ('sugar', 'bread'), ('bread', 'tea'), ('bread', 'cereal'), ('bread', 'milk'), ('bread', 'orange'), ('bread', 'coffee'), ('bread', 'jam'), ('bread', 'biscuit'), ('bread', 'sugar')]\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# Import permutations from the itertools module\n",
    "from itertools import permutations\n",
    "\n",
    "# Define the set of groceries\n",
    "flattened = [i for t in transactions for i in t]\n",
    "groceries = list(set(flattened))\n",
    "\n",
    "# Generate all possible rules\n",
    "rules = list(permutations(groceries, 2))\n",
    "\n",
    "# Print the set of rules\n",
    "print(rules)\n",
    "\n",
    "# Print the number of rules\n",
    "print(len(rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding transaction data\n",
    "-  we will use a common pipeline for preprocessing data for use in market basket analysis. The first step is to import a pandas DataFrame and select the column that contains transactions. Each transaction in the column will be a string that consists of a number of items, each separated by a comma. The next step is to use a lambda function to split each transaction string into a list, thereby transforming the column into a list of lists.\n",
    "-  transform transactions into a one-hot encoded DataFrame, where each column consists of TRUE and FALSE values that indicate whether an item was included in a transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>milk,bread,biscuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bread,milk,biscuit,cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bread,tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jam,bread,milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tea,biscuit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Transaction\n",
       "0         milk,bread,biscuit\n",
       "1  bread,milk,biscuit,cereal\n",
       "2                  bread,tea\n",
       "3             jam,bread,milk\n",
       "4                tea,biscuit"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the transaction encoder function from mlxtend\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "\n",
    "transactions = pd.read_csv('data/small_grocery_store.csv')\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['milk', 'bread', 'biscuit'], ['bread', 'milk', 'biscuit', 'cereal'], ['bread', 'tea'], ['jam', 'bread', 'milk'], ['tea', 'biscuit'], ['bread', 'tea'], ['tea', 'cereal'], ['bread', 'tea', 'biscuit'], ['jam', 'bread', 'tea'], ['bread', 'milk'], ['coffee', 'orange', 'biscuit', 'cereal'], ['coffee', 'orange', 'biscuit', 'cereal'], ['coffee', 'sugar'], ['bread', 'coffee', 'orange'], ['bread', 'sugar', 'biscuit'], ['coffee', 'sugar', 'cereal'], ['bread', 'sugar', 'biscuit'], ['bread', 'coffee', 'sugar'], ['bread', 'coffee', 'sugar'], ['tea', 'milk', 'coffee', 'cereal']]\n"
     ]
    }
   ],
   "source": [
    "transactions = transactions['Transaction'].apply(lambda x:x.split(','))\n",
    "transactions = list(transactions)\n",
    "print(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    biscuit  bread  cereal  coffee    jam   milk  orange  sugar    tea\n",
      "0      True   True   False   False  False   True   False  False  False\n",
      "1      True   True    True   False  False   True   False  False  False\n",
      "2     False   True   False   False  False  False   False  False   True\n",
      "3     False   True   False   False   True   True   False  False  False\n",
      "4      True  False   False   False  False  False   False  False   True\n",
      "5     False   True   False   False  False  False   False  False   True\n",
      "6     False  False    True   False  False  False   False  False   True\n",
      "7      True   True   False   False  False  False   False  False   True\n",
      "8     False   True   False   False   True  False   False  False   True\n",
      "9     False   True   False   False  False   True   False  False  False\n",
      "10     True  False    True    True  False  False    True  False  False\n",
      "11     True  False    True    True  False  False    True  False  False\n",
      "12    False  False   False    True  False  False   False   True  False\n",
      "13    False   True   False    True  False  False    True  False  False\n",
      "14     True   True   False   False  False  False   False   True  False\n",
      "15    False  False    True    True  False  False   False   True  False\n",
      "16     True   True   False   False  False  False   False   True  False\n",
      "17    False   True   False    True  False  False   False   True  False\n",
      "18    False   True   False    True  False  False   False   True  False\n",
      "19    False  False    True    True  False   True   False  False   True\n"
     ]
    }
   ],
   "source": [
    "# Instantiate transaction encoder and identify unique items\n",
    "encoder = TransactionEncoder().fit(transactions)\n",
    "\n",
    "# One-hot encode transactions\n",
    "onehot = encoder.transform(transactions)\n",
    "\n",
    "# Convert one-hot encoded data to DataFrame\n",
    "onehot = pd.DataFrame(onehot, columns = encoder.columns_)\n",
    "\n",
    "# Print the one-hot encoded transaction dataset\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biscuit    0.40\n",
      "bread      0.65\n",
      "cereal     0.30\n",
      "coffee     0.40\n",
      "jam        0.10\n",
      "milk       0.25\n",
      "orange     0.15\n",
      "sugar      0.30\n",
      "tea        0.35\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the support\n",
    "support = onehot.mean()\n",
    "\n",
    "# Print the support\n",
    "print(support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biscuit      0.40\n",
      "bread        0.65\n",
      "cereal       0.30\n",
      "coffee       0.40\n",
      "jam          0.10\n",
      "milk         0.25\n",
      "orange       0.15\n",
      "sugar        0.30\n",
      "tea          0.35\n",
      "jam+bread    0.10\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add a jam+bread column to the DataFrame onehot\n",
    "onehot['jam+bread'] = np.logical_and(onehot['jam'], onehot['bread'])\n",
    "\n",
    "# Compute the support\n",
    "support = onehot.mean()\n",
    "\n",
    "# Print the support values\n",
    "print(support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we'll start working with much larger datasets, where it will be necessary to prune both items and rules by support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommending books with support\n",
    "- A library wants to get members to read more and has decided to use market basket analysis to figure out how. They approach to do the analysis and ask that we use the five most highly-rated books from the goodbooks-10k dataset.\n",
    "- Each column in the DataFrame corresponds to a book and has the value TRUE if the book is contained in a reader's library and is rated highly. \n",
    "\n",
    "      Hunger  Potter  Twilight\n",
    "      \n",
    "0      False    True     False\n",
    "1      False    True      True\n",
    "2      False   False     False\n",
    "3      False    True     False\n",
    "4      False   False     False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute support for Hunger and Potter\n",
    "supportHP = np.logical_and(books['Hunger'], books['Potter']).mean()\n",
    "\n",
    "# Compute support for Hunger and Twilight\n",
    "supportHT = np.logical_and(books['Hunger'], books['Twilight']).mean()\n",
    "\n",
    "# Compute support for Potter and Twilight\n",
    "supportPT = np.logical_and(books['Potter'], books['Twilight']).mean()\n",
    "\n",
    "# Print support values\n",
    "print(\"Hunger Games and Harry Potter: %.2f\" % supportHP)\n",
    "print(\"Hunger Games and Twilight: %.2f\" % supportHT)\n",
    "print(\"Harry Potter and Twilight: %.2f\" % supportPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hunger Games and Harry Potter: 0.12\n",
    "- Hunger Games and Twilight: 0.09\n",
    "- Harry Potter and Twilight: 0.14\n",
    "\n",
    "\n",
    "- Based on the support metric, Harry Potter and Twilight appear to be the best options for cross-promotion. In the next problem, we'll consider whether we should use Harry Potter to promote Twilight or Twilight to promote Harry Potter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining support with confidence\n",
    "- After reporting your findings from the previous exercise, the library asks you about the direction of the relationship. Should they use Harry Potter to promote Twilight or Twilight to promote Harry Potter?\n",
    "\n",
    "- After thinking about this, we decide to compute the confidence metric, which has a direction, unlike support. We'll compute it for both {Potter} →{Twilight} and {Twilight} → {Potter}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute support for Potter and Twilight\n",
    "supportPT = np.logical_and(books['Potter'], books['Twilight']).mean()\n",
    "\n",
    "# Compute support for Potter\n",
    "supportP = books['Potter'].mean()\n",
    "\n",
    "# Compute support for Twilight\n",
    "supportT = books['Twilight'].mean()\n",
    "\n",
    "# Compute confidence for both rules\n",
    "confidencePT = supportPT / supportP\n",
    "confidenceTP = supportPT / supportT\n",
    "\n",
    "# Print results\n",
    "print('{0:.2f}, {1:.2f}'.format(confidencePT, confidenceTP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0.29, 0.55\n",
    "- Even though the support is identical for the two association rules, the confidence is much higher for Twilight -> Harry Potter, since Harry Potter has a higher support than Twilight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further refinement with lift\n",
    "- Once again, we report our results to the library: Use Twilight to promote Harry Potter, since the rule has a higher confidence metric. The library thanks us for the suggestion, but asks us to confirm that this is a meaningful relationship using another metric.\n",
    "- We recall that lift may be useful here. If lift is less than 1, this means that Harry Potter and Twilight are paired together less frequently than we would expect if the pairings occurred by random chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute support for Potter and Twilight\n",
    "supportPT = np.logical_and(books['Potter'], books['Twilight']).mean()\n",
    "\n",
    "# Compute support for Potter\n",
    "supportP = books['Potter'].mean()\n",
    "\n",
    "# Compute support for Twilight\n",
    "supportT = books['Twilight'].mean()\n",
    "\n",
    "# Compute lift\n",
    "lift = supportPT / (supportP * supportT)\n",
    "\n",
    "# Print lift\n",
    "print(\"Lift: %.2f\" % lift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-     Lift: 1.15\n",
    "- As it turns out, lift is greater than 1.0. This could give us some confidence that the association rule we recommended did not arise by random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
